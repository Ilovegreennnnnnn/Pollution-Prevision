{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fd2d3961bd98c5",
   "metadata": {},
   "source": [
    "### 1. Importer les bibliothèques\n",
    "Importation de toutes les bibliothèques nécessaires pour la manipulation des données, la visualisation, le prétraitement, la modélisation et l'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b843c9118160b36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:46:56.189598Z",
     "start_time": "2025-04-28T20:46:56.186946Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import glob\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56702aaefb6e6f5e",
   "metadata": {},
   "source": [
    "### 2. Charger les données\n",
    "Chargement du jeu de données depuis le fichier CSV spécifié.\n",
    "*Note : Assurez-vous que le chemin `\\\\France_Air_Quality\\\\DataExtract.csv` est correct par rapport à l'emplacement de votre notebook ou fournissez un chemin absolu. Utiliser des chaînes brutes `r'...'` ou des barres obliques `/` peut parfois être plus fiable sur différents systèmes d'exploitation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c40d2885f4b25bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:47:00.308245Z",
     "start_time": "2025-04-28T20:46:58.878200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des Données depuis : C:\\Projet_ESME\\Pollution\\Pollution\\France_Air_Quality\n",
      "Chargement des Données terminé : 42 fichiers concaténés\n",
      "Nombre de lignes : 584379\n",
      "Chargement des Données terminé : 42 fichiers concaténés\n",
      "Nombre de lignes : 584379\n"
     ]
    }
   ],
   "source": [
    "data_directory = r\"C:\\Projet_ESME\\Pollution\\Pollution\\France_Air_Quality\"\n",
    "\n",
    "print(f\"Chargement des Données depuis : {data_directory}\")\n",
    "df = None \n",
    "\n",
    "csvs = os.path.join(data_directory, \"*.csv\")\n",
    "csv_files = glob.glob(csvs)\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    temp_df = pd.read_csv(file, low_memory=False)\n",
    "    df_list.append(temp_df)\n",
    "        \n",
    "    if df_list:\n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(f\"Chargement des Données terminé : {len(df_list)} fichiers concaténés\")\n",
    "print(f\"Nombre de lignes : {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab6fccd27078ee",
   "metadata": {},
   "source": [
    "### 3. Exploration Initiale et Visualisation des Manquants\n",
    "Affichage des premières lignes, des informations générales et visualisation des valeurs manquantes si les données ont été chargées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5453baf8ce316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:47:07.330906Z",
     "start_time": "2025-04-28T20:47:05.355835Z"
    }
   },
   "outputs": [],
   "source": [
    "def exploration_initiale(df):\n",
    "    if df is not None:\n",
    "        print(\"\\n Exploration Initiale \")\n",
    "        print(\"Aperçu des 5 premières lignes :\")\n",
    "        display(df.head())\n",
    "\n",
    "        print(\"\\nInformations sur le DataFrame :\")\n",
    "        display(df.info())\n",
    "\n",
    "        print(\"\\n Visualisation des Valeurs Manquantes \")\n",
    "        print(\"\\nVisualisation (Matrice)...\")\n",
    "        try:\n",
    "            msno.matrix(df)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la création de la matrice missingno : {e}\")\n",
    "\n",
    "        print(\"\\nVisualisation (Heatmap)...\")\n",
    "        try:\n",
    "            msno.heatmap(df)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la création de la heatmap missingno : {e}\")\n",
    "    else:\n",
    "        print(\"DataFrame non chargé, exploration impossible.\")\n",
    "\n",
    "exploration_initiale(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add1db1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Distribution des Polluants dans la colonne 'Air Pollutant' -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Air Pollutant",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Frequency",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fafd25a1-29b0-4bf3-860b-ca9599fa22c7",
       "rows": [
        [
         "0",
         "O3",
         "187777"
        ],
        [
         "1",
         "NO2",
         "130374"
        ],
        [
         "2",
         "PM10",
         "90120"
        ],
        [
         "3",
         "SO2",
         "80948"
        ],
        [
         "4",
         "NO",
         "27170"
        ],
        [
         "5",
         "PM2.5",
         "24318"
        ],
        [
         "6",
         "CO",
         "11802"
        ],
        [
         "7",
         "NOX as NO2",
         "11639"
        ],
        [
         "8",
         "NOX",
         "5248"
        ],
        [
         "9",
         "C6H6",
         "3271"
        ],
        [
         "10",
         "SPM",
         "954"
        ],
        [
         "11",
         "BaP in PM10",
         "928"
        ],
        [
         "12",
         "SA",
         "855"
        ],
        [
         "13",
         "Pb in PM10",
         "838"
        ],
        [
         "14",
         "As in PM10",
         "784"
        ],
        [
         "15",
         "Cd in PM10",
         "759"
        ],
        [
         "16",
         "Ni in PM10",
         "758"
        ],
        [
         "17",
         "C6H5-CH3",
         "633"
        ],
        [
         "18",
         "C6H5-C2H5",
         "477"
        ],
        [
         "19",
         "o-C6H4-(CH3)2",
         "461"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air Pollutant</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O3</td>\n",
       "      <td>187777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO2</td>\n",
       "      <td>130374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PM10</td>\n",
       "      <td>90120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO2</td>\n",
       "      <td>80948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO</td>\n",
       "      <td>27170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PM2.5</td>\n",
       "      <td>24318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CO</td>\n",
       "      <td>11802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NOX as NO2</td>\n",
       "      <td>11639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOX</td>\n",
       "      <td>5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C6H6</td>\n",
       "      <td>3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SPM</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BaP in PM10</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SA</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pb in PM10</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>As in PM10</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cd in PM10</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ni in PM10</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C6H5-CH3</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C6H5-C2H5</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>o-C6H4-(CH3)2</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Air Pollutant  Frequency\n",
       "0              O3     187777\n",
       "1             NO2     130374\n",
       "2            PM10      90120\n",
       "3             SO2      80948\n",
       "4              NO      27170\n",
       "5           PM2.5      24318\n",
       "6              CO      11802\n",
       "7      NOX as NO2      11639\n",
       "8             NOX       5248\n",
       "9            C6H6       3271\n",
       "10            SPM        954\n",
       "11    BaP in PM10        928\n",
       "12             SA        855\n",
       "13     Pb in PM10        838\n",
       "14     As in PM10        784\n",
       "15     Cd in PM10        759\n",
       "16     Ni in PM10        758\n",
       "17       C6H5-CH3        633\n",
       "18      C6H5-C2H5        477\n",
       "19  o-C6H4-(CH3)2        461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre total de types de polluants uniques trouvés : 102\n",
      "\n",
      "Liste des 20 polluants les plus fréquents : ['O3', 'NO2', 'PM10', 'SO2', 'NO', 'PM2.5', 'CO', 'NOX as NO2', 'NOX', 'C6H6', 'SPM', 'BaP in PM10', 'SA', 'Pb in PM10', 'As in PM10', 'Cd in PM10', 'Ni in PM10', 'C6H5-CH3', 'C6H5-C2H5', 'o-C6H4-(CH3)2']\n"
     ]
    }
   ],
   "source": [
    "def analyze_pollutant_distribution(df, pollutant_col='Air Pollutant', print_results=True):\n",
    "    if df is not None and pollutant_col in df.columns:\n",
    "        # 1. Compter les occurrences des polluants\n",
    "        pollutant_counts = df[pollutant_col].value_counts(dropna=True)\n",
    "        \n",
    "        # 2. Transformer la Série en DataFrame et garder les 20 premiers en termes de fréquence\n",
    "        pollutant_table = pollutant_counts.reset_index().head(20)\n",
    "        pollutant_table.columns = [pollutant_col, 'Frequency']\n",
    "        \n",
    "        # 3. Trier le DataFrame par fréquence (ordre décroissant)\n",
    "        pollutant_table_sorted = pollutant_table.sort_values(by='Frequency', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        # Extraire les 20 polluants les plus fréquents en liste\n",
    "        top_pollutants_list = pollutant_table_sorted[pollutant_col].tolist()\n",
    "\n",
    "        # Affichage optionnel des résultats\n",
    "        if print_results:\n",
    "            print(f\"----- Distribution des Polluants dans la colonne '{pollutant_col}' -----\")\n",
    "            try:\n",
    "                display(pollutant_table_sorted)\n",
    "            except NameError:\n",
    "                print(pollutant_table_sorted.to_string())  # .to_string() pour afficher tout sans troncature\n",
    "            print(f\"\\nNombre total de types de polluants uniques trouvés : {len(pollutant_counts)}\")\n",
    "            print(f\"\\nListe des 20 polluants les plus fréquents : {top_pollutants_list}\")\n",
    "\n",
    "        return pollutant_table_sorted, top_pollutants_list\n",
    "    else:\n",
    "        print(f\"Erreur : Le DataFrame est vide ou la colonne '{pollutant_col}' est absente.\")\n",
    "        return None, None\n",
    "\n",
    "# Appel de la fonction pour analyser la distribution des polluants\n",
    "pollutant_table, top_pollutants = analyze_pollutant_distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a14fc",
   "metadata": {},
   "source": [
    "Pour la suite, nous allons sélectionner les polluants suivants et générer un modèle spécifique pour chacun : ['O3', 'NO2', 'PM10', 'SO2', 'NO', 'PM2.5', 'CO', 'NOX']."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d529e8cc3897ce",
   "metadata": {},
   "source": [
    "### 4. Nettoyage des Données\n",
    "Suppression des colonnes jugées inutiles et des lignes où la variable cible (`Air Pollution Level`) est manquante ou non numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94f7a1bec8e5335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:47:29.100132Z",
     "start_time": "2025-04-28T20:47:29.034223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Nettoyage des Données ---\n",
      "Colonnes supprimées : 15\n",
      "Dimensions après suppression colonnes : (584379, 12)\n",
      "Lignes supprimées (cible manquante ou non numérique) : 1313\n",
      " -> Dont 1313 lignes avec cible non-numérique convertie en NaN.\n",
      "Dimensions après suppression lignes : (583066, 12)\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    print(\"\\n--- Nettoyage des Données ---\")\n",
    "    # 4.1 Suppression des Colonnes\n",
    "    initial_cols = df.shape[1]\n",
    "    drop_cols = ['Country', 'Air Quality Network', 'Air Quality Network Name',\n",
    "                 'Air Quality Station EoI Code', 'Air Quality Station Name',\n",
    "                 'Sampling Point Id','Air Pollutant Descritpion', 'Data Aggregation Process Id',\n",
    "                 'Data Aggregation Process', 'Unit Of Air Pollution Level',\n",
    "                 'Verification', 'City Code', 'Source Of Data Flow',\n",
    "                 'Calculation Time', 'Link to raw data (only E1a/validated data from AQ e-Reporting)',\n",
    "                 'Observation Frequency']\n",
    "\n",
    "    cols_to_drop_existing = [col for col in drop_cols if col in df.columns]\n",
    "    if cols_to_drop_existing:\n",
    "        df.drop(columns=cols_to_drop_existing, inplace=True)\n",
    "        print(f\"Colonnes supprimées : {len(cols_to_drop_existing)}\")\n",
    "    else:\n",
    "        print(\"Aucune des colonnes spécifiées pour suppression n'a été trouvée.\")\n",
    "    print(f\"Dimensions après suppression colonnes : {df.shape}\")\n",
    "\n",
    "    # 4.2 Traitement de la Cible et Suppression des Lignes Manquantes/Invalides\n",
    "    if 'Air Pollution Level' in df.columns:\n",
    "        initial_rows = df.shape[0]\n",
    "        df['Air Pollution Level'] = pd.to_numeric(df['Air Pollution Level'], errors='coerce')\n",
    "        rows_before_nan_drop = df.shape[0]\n",
    "        df.dropna(subset=['Air Pollution Level'], inplace=True)\n",
    "        rows_after_nan_drop = df.shape[0]\n",
    "        print(f\"Lignes supprimées (cible manquante ou non numérique) : {initial_rows - rows_after_nan_drop}\")\n",
    "        if rows_before_nan_drop > rows_after_nan_drop :\n",
    "            print(f\" -> Dont {rows_before_nan_drop - rows_after_nan_drop} lignes avec cible non-numérique convertie en NaN.\")\n",
    "        print(f\"Dimensions après suppression lignes : {df.shape}\")\n",
    "    else:\n",
    "        print(\"AVERTISSEMENT : Colonne cible 'Air Pollution Level' non trouvée.\")\n",
    "\n",
    "    # Vérifier si le DataFrame est vide après nettoyage\n",
    "    if df.empty:\n",
    "        print(\"\\n *** ATTENTION : Le DataFrame est vide après nettoyage. Les étapes suivantes échoueront. ***\")\n",
    "        df = None # Marquer df comme invalide\n",
    "else:\n",
    "    print(\"DataFrame non chargé, nettoyage impossible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a736c4cae9d564",
   "metadata": {},
   "source": [
    "### 5. Séparation Features / Cible et Identification des Types\n",
    "Séparation des variables explicatives (X) et de la cible (y), puis identification des colonnes numériques et catégorielles à utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4bd5c6d04c71241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:47:37.985818Z",
     "start_time": "2025-04-28T20:47:37.960554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X, y, num_features, cat_features = None, None, [], [] # Initialisation\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- Séparation Features / Cible et Identification Types ---\")\n",
    "    if 'Air Pollution Level' in df.columns:\n",
    "        X = df.drop(columns=['Air Pollution Level'])\n",
    "        y = df['Air Pollution Level']\n",
    "        print(f\"Dimensions Features (X) : {X.shape}\")\n",
    "        print(f\"Dimensions Cible (y) : {y.shape}\")\n",
    "\n",
    "        num_features_potential = ['Year', 'Longitude', 'Latitude', 'Altitude', 'City Population']\n",
    "        cat_features_potential = ['Air Pollutant', 'Air Quality Station Type', 'Air Quality Station Area', 'City']\n",
    "\n",
    "        num_features = [col for col in num_features_potential if col in X.columns]\n",
    "        cat_features = [col for col in cat_features_potential if col in X.columns]\n",
    "\n",
    "        print(f\"\\nFeatures numériques identifiées : {num_features}\")\n",
    "        print(f\"Features catégorielles identifiées : {cat_features}\")\n",
    "\n",
    "        # Vérification des colonnes non traitées\n",
    "        all_features_in_transformer = set(num_features + cat_features)\n",
    "        all_columns_in_X = set(X.columns)\n",
    "        unhandled_columns = all_columns_in_X - all_features_in_transformer\n",
    "        if unhandled_columns:\n",
    "            print(f\"\\nColonnes non explicitement traitées (seront affectées par 'remainder') : {unhandled_columns}\")\n",
    "        else:\n",
    "            print(\"\\nToutes les colonnes de X sont prises en compte par les features numériques ou catégorielles.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Colonne cible 'Air Pollution Level' non trouvée dans le DataFrame nettoyé.\")\n",
    "else:\n",
    "    print(\"DataFrame non disponible pour la séparation Features/Cible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646fb2d1eff0e82",
   "metadata": {},
   "source": [
    "### 6. Définition du Pipeline de Prétraitement\n",
    "Création d'un `ColumnTransformer` pour appliquer l'imputation et la mise à l'échelle/encodage aux différents types de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8090bb83ea36b972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:47:46.678896Z",
     "start_time": "2025-04-28T20:47:46.674754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "preprocessor = None # Initialisation\n",
    "\n",
    "if X is not None and (num_features or cat_features):\n",
    "    print(\"\\n--- Définition du Pipeline de Prétraitement ---\")\n",
    "    transformers_list = []\n",
    "\n",
    "    if num_features:\n",
    "        num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        transformers_list.append(('num', num_pipeline, num_features))\n",
    "        print(\"Pipeline numérique défini (Imputer + Scaler).\")\n",
    "\n",
    "    if cat_features:\n",
    "        cat_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "        transformers_list.append(('cat', cat_pipeline, cat_features))\n",
    "        print(\"Pipeline catégoriel défini (Imputer + OneHotEncoder).\")\n",
    "\n",
    "    # 'remainder=drop' pour supprimer les colonnes non listées explicitement\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers_list,\n",
    "        remainder='drop'\n",
    "    )\n",
    "    print(f\"Pipeline de prétraitement final défini (remainder='{preprocessor.remainder}').\")\n",
    "else:\n",
    "    print(\"Impossible de définir le pipeline de prétraitement (X manquant ou aucune feature identifiée).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48d4f88efe5ed2",
   "metadata": {},
   "source": [
    "### 7. Séparation Train / Test (Division Temporelle)\n",
    "Division des données en ensembles d'entraînement et de test en respectant l'ordre chronologique basé sur l'année (`Year`) pour une évaluation réaliste. Utilisation de la méthode proportionnelle sur données triées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799718748ddeaf11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:47:51.628727Z",
     "start_time": "2025-04-28T20:47:51.520780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = None, None, None, None # Initialisation\n",
    "\n",
    "if df is not None and X is not None and y is not None : # S'assurer que df, X et y existent\n",
    "    print(\"\\n--- Séparation Train / Test (Division Temporelle) ---\")\n",
    "\n",
    "    # 1. Trier le DataFrame COMPLET (avant de séparer X et y !) par année\n",
    "    # Utiliser le df nettoyé qui contient encore X et y\n",
    "    df_sorted = df.sort_values(by='Year').reset_index(drop=True)\n",
    "    print(f\"Données triées par année. Année min: {df_sorted['Year'].min()}, Année max: {df_sorted['Year'].max()}\")\n",
    "\n",
    "    # 2. Définir la proportion pour le test set\n",
    "    test_proportion = 0.20 # 20% des données les plus récentes pour le test\n",
    "    split_index = int(len(df_sorted) * (1 - test_proportion))\n",
    "    print(f\"Index de coupure pour {test_proportion*100:.0f}% de test : {split_index} (sur {len(df_sorted)} lignes)\")\n",
    "\n",
    "    # 3. Créer les DataFrames train/test à partir du DataFrame trié\n",
    "    df_train = df_sorted.iloc[:split_index].copy()\n",
    "    df_test = df_sorted.iloc[split_index:].copy()\n",
    "\n",
    "    # 4. Séparer X et y DANS chaque ensemble (train et test)\n",
    "    if not df_train.empty and 'Air Pollution Level' in df_train.columns:\n",
    "        X_train = df_train.drop(columns=['Air Pollution Level'])\n",
    "        y_train = df_train['Air Pollution Level']\n",
    "    else:\n",
    "         print(\"ERREUR: df_train est vide ou manque la colonne cible.\")\n",
    "\n",
    "    if not df_test.empty and 'Air Pollution Level' in df_test.columns:\n",
    "        X_test = df_test.drop(columns=['Air Pollution Level'])\n",
    "        y_test = df_test['Air Pollution Level']\n",
    "    else:\n",
    "         print(\"ERREUR: df_test est vide ou manque la colonne cible.\")\n",
    "\n",
    "\n",
    "    # 5. Vérifier les tailles et la couverture temporelle\n",
    "    if X_train is not None and X_test is not None:\n",
    "        print(f\"\\nTaille Train Set (X/y): {X_train.shape[0]}\")\n",
    "        print(f\"Années couvertes par Train: {df_train['Year'].min()} - {df_train['Year'].max()}\")\n",
    "        print(f\"Taille Test Set (X/y): {X_test.shape[0]}\")\n",
    "        print(f\"Années couvertes par Test: {df_test['Year'].min()} - {df_test['Year'].max()}\")\n",
    "    else:\n",
    "        print(\"Problème lors de la création de X/y train ou test après la division temporelle.\")\n",
    "\n",
    "else:\n",
    "    print(\"Impossible de faire la séparation Train/Test (df, X ou y manquants).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf5ccda5127e10",
   "metadata": {},
   "source": [
    "### 8. Création et Entraînement du Modèle\n",
    "Définition du pipeline final intégrant le prétraitement et le modèle `RandomForestRegressor`, puis entraînement sur l'ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384d5c2ab96e2aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:49:07.449550Z",
     "start_time": "2025-04-28T20:48:03.556476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = None # Initialisation\n",
    "\n",
    "if preprocessor is not None and X_train is not None and y_train is not None:\n",
    "    print(\"\\n--- Création et Entraînement du Modèle ---\")\n",
    "\n",
    "    # Création du pipeline final Modèle\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    print(\"Entraînement du modèle RandomForestRegressor...\")\n",
    "    try:\n",
    "        # Vérification finale du type de y_train\n",
    "        if not pd.api.types.is_numeric_dtype(y_train):\n",
    "             print(\"ERREUR critique : y_train n'est pas numérique avant l'entraînement !\")\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            print(\"Entraînement terminé.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue pendant l'entraînement : {e}\")\n",
    "        model = None # Invalider le modèle\n",
    "\n",
    "else:\n",
    "    print(\"Impossible de créer ou entraîner le modèle (prérequis manquants).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a2f9762195d85",
   "metadata": {},
   "source": [
    "### 9. Prédiction sur l'Ensemble de Test\n",
    "Utilisation du modèle entraîné pour faire des prédictions sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c1b3b64c81e171a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:49:53.084902Z",
     "start_time": "2025-04-28T20:49:52.679161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "y_pred = None # Initialisation\n",
    "\n",
    "if model is not None and X_test is not None:\n",
    "    print(\"\\n--- Prédiction sur l'Ensemble de Test ---\")\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"Prédictions réalisées.\")\n",
    "        print(f\"Exemple de 5 premières prédictions : {y_pred[:5]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue pendant la prédiction : {e}\")\n",
    "        y_pred = None\n",
    "else:\n",
    "    print(\"Impossible de faire des prédictions (modèle non entraîné ou X_test manquant).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576c5ef265ff19d",
   "metadata": {},
   "source": [
    "### 10. Évaluation du Modèle\n",
    "Calcul des métriques MSE et RMSE pour évaluer la performance du modèle sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8550fa6c5fe75769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:49:58.309182Z",
     "start_time": "2025-04-28T20:49:58.079170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "if y_test is not None and y_pred is not None:\n",
    "    print(\"\\n--- Évaluation du Modèle ---\")\n",
    "    try:\n",
    "        # Vérification finale du type de y_test\n",
    "        if not pd.api.types.is_numeric_dtype(y_test):\n",
    "            print(\"AVERTISSEMENT: y_test n'est pas numérique, tentative de nettoyage...\")\n",
    "            y_test_numeric = pd.to_numeric(y_test, errors='coerce')\n",
    "            valid_indices_test = ~y_test_numeric.isna()\n",
    "            if not valid_indices_test.all():\n",
    "                 initial_len = len(y_test_numeric)\n",
    "                 y_test_cleaned = y_test_numeric[valid_indices_test]\n",
    "                 y_pred_cleaned = y_pred[valid_indices_test] # Filtrer y_pred aussi!\n",
    "                 print(f\"Suppression de {initial_len - len(y_test_cleaned)} lignes où y_test n'était pas numérique.\")\n",
    "                 if len(y_test_cleaned) != len(y_pred_cleaned):\n",
    "                      print(\"ERREUR: Mismatch de longueur après nettoyage y_test/y_pred.\")\n",
    "                      raise ValueError(\"Incohérence des longueurs après nettoyage de y_test.\")\n",
    "                 y_test_eval = y_test_cleaned\n",
    "                 y_pred_eval = y_pred_cleaned\n",
    "            else:\n",
    "                 y_test_eval = y_test_numeric\n",
    "                 y_pred_eval = y_pred # Pas besoin de filtrer y_pred si y_test était ok\n",
    "\n",
    "        else:\n",
    "             y_test_eval = y_test\n",
    "             y_pred_eval = y_pred\n",
    "\n",
    "        if y_test_eval.empty:\n",
    "             print(\"ERREUR: y_test est vide après nettoyage. Impossible d'évaluer.\")\n",
    "        else:\n",
    "            mse = mean_squared_error(y_test_eval, y_pred_eval)\n",
    "            rmse = np.sqrt(mse) # Calcul manuel de RMSE\n",
    "            print(f\"Erreur Quadratique Moyenne (MSE) : {mse:.4f}\")\n",
    "            print(f\"Racine de l'Erreur Quadratique Moyenne (RMSE) : {rmse:.4f}\")\n",
    "\n",
    "            # Affichage du graphique Prédit vs Réel\n",
    "            print(\"\\nAffichage du graphique Prédit vs Réel...\")\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            sns.scatterplot(x=y_test_eval, y=y_pred_eval, alpha=0.5)\n",
    "            # Déterminer les limites pour la ligne diagonale\n",
    "            min_val = min(y_test_eval.min(), y_pred_eval.min())\n",
    "            max_val = max(y_test_eval.max(), y_pred_eval.max())\n",
    "            plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--') # Ligne y=x\n",
    "            plt.xlabel(\"Vraies Valeurs (y_test)\")\n",
    "            plt.ylabel(\"Valeurs Prédites (y_pred)\")\n",
    "            plt.title(\"Comparaison Valeurs Prédites vs Réelles (Test Set)\")\n",
    "            plt.grid(True)\n",
    "            # Limiter les axes pour mieux voir la dispersion si les valeurs sont très grandes\n",
    "            # plt.xlim(min_val, max_val)\n",
    "            # plt.ylim(min_val, max_val)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue lors de l'évaluation : {e}\")\n",
    "else:\n",
    "    print(\"Impossible d'évaluer le modèle (y_test ou y_pred manquants/invalides).\")\n",
    "\n",
    "print(\"\\n--- Fin du Notebook ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
